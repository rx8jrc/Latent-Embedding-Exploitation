{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1692417508428,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "qIRQyegn_slQ"
   },
   "outputs": [],
   "source": [
    "''' Importing libraries '''\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "from tensorflow import keras\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model, Sequential, load_model, clone_model\n",
    "from keras.layers import LSTM, Dense\n",
    "from google.colab import files\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Function to read csv_file '''\n",
    "\n",
    "def read_data(csv_file, column_no, after_column_no):\n",
    "  df = pd.read_csv(csv_file)\n",
    "  if after_column_no==True:\n",
    "    df = df.iloc[: , column_no:]\n",
    "  else:\n",
    "    df = df.iloc[: , :column_no]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1692417508429,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "u-I6yL0Y_vL0"
   },
   "outputs": [],
   "source": [
    "''' Function to add gestures and subjects to an empty dataframe '''\n",
    "\n",
    "def adding_dataframe(df_new, df_original, ids_list, gestures_list):\n",
    "  for id in ids_list:\n",
    "    for item in gestures_list:\n",
    "      df_new = df_new.append(df_original[(df_original['userId']==id) & (df_original['gesture']==item)])\n",
    "  return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1692417508430,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "neT4JV_ORJCe"
   },
   "outputs": [],
   "source": [
    "'''Function for random subject-wise splitting'''\n",
    "\n",
    "def leave_subject(curr_df,n=1):\n",
    "  ids =[]\n",
    "  user_ids= np.unique(curr_df['userId'])\n",
    "  for i in range(n):\n",
    "   id = random.choice(user_ids)\n",
    "   ids.append(id)\n",
    "   indices = np.where(user_ids==id)\n",
    "   user_ids = np.delete(user_ids, indices)\n",
    "  test= curr_df[curr_df['userId'].isin(ids)]\n",
    "  train = curr_df[~curr_df['userId'].isin(ids)]\n",
    "  return train,test,ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1692417508432,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "inADBIlr_zP9"
   },
   "outputs": [],
   "source": [
    "''' Function to prepare data '''\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "def create_dataset(X, y, time_steps=1, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X), step):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(v)\n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "        # ys.append(y.iloc[i])\n",
    "\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1692417508432,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "gHjfjGrERMly"
   },
   "outputs": [],
   "source": [
    "''' Function to scale data '''\n",
    "\n",
    "def scaling_dataframe(df_train, df_val, scale_columns):\n",
    "  scaler = RobustScaler()\n",
    "  scaler = scaler.fit(df_train[scale_columns])\n",
    "\n",
    "  df_train.loc[:, scale_columns] = scaler.transform(df_train[scale_columns].to_numpy())\n",
    "  df_val.loc[:, scale_columns] = scaler.transform(df_val[scale_columns].to_numpy())\n",
    "\n",
    "  return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1692417508433,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "MQkm664o_7WH"
   },
   "outputs": [],
   "source": [
    "''' Function for LSTM architecture '''\n",
    "\n",
    "def lstm_model(time_steps, features, u1, d1, u2, out):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(units=u1, input_shape=(time_steps, features), return_sequences=False))\n",
    "  model.add(keras.layers.Dropout(rate=d1))\n",
    "  model.add(Dense(units=u2, activation='relu'))\n",
    "  model.add(Dense(out, activation='softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1692417510204,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "8DuPQyBdNj0D"
   },
   "outputs": [],
   "source": [
    "'''Custom label encoding function'''\n",
    "\n",
    "def custom_label_encode(data, mapping):\n",
    "    encoded_labels = [mapping[item[0]] for item in data]\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1692417513913,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "5yYJDoN4K2ss",
    "outputId": "a76b9d15-d525-42b1-c8bc-98f56b34bda2"
   },
   "outputs": [],
   "source": [
    "# Read control subject's data from csv\n",
    "df = read_data('control-gesture-data-source.csv', 2, True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1692417517157,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "bdoljlCx681x"
   },
   "outputs": [],
   "source": [
    "train_ids = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "gestures_source = ['right', 'left', 'square_C', 'square_AC', 'upRight', 'upLeft', 'rightDown', 'leftDown',\n",
    "                   'v', 'v_Mirror', 'v_Reverse', 'v_ReverseM', 's_Top', 's_TopM', 's_Down', 's_DownM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1692417525446,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "L1OTfET67pwZ",
    "outputId": "dba05e46-2908-43dd-fd00-4010b7b47340"
   },
   "outputs": [],
   "source": [
    "df_source = pd.DataFrame(columns=['x_axis', 'y_axis', 'z_axis', 'gesture', 'userId'])\n",
    "df_source = adding_dataframe(df_source, df, train_ids, gestures_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1692417552932,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "S8x2w9Fv7b0B"
   },
   "outputs": [],
   "source": [
    "df_train, df_val, ids_val = leave_subject(df_source,n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1692417553628,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "lk9V5VUw7d6x",
    "outputId": "0c84e064-b329-431c-b256-d5940dd53966"
   },
   "outputs": [],
   "source": [
    "print(df_train.userId.unique())\n",
    "print(df_val.userId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1692417555659,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "1lBcaxYU7f-m",
    "outputId": "111a1f8f-1c77-4c8c-c6e8-c035a1e80a4f"
   },
   "outputs": [],
   "source": [
    "# Scale data\n",
    "\n",
    "scale_columns = ['x_axis', 'y_axis', 'z_axis']\n",
    "df_train, df_val = scaling_dataframe(df_train, df_val, scale_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1692417571221,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "qGoPUbAE7j4l",
    "outputId": "48a6d8f5-10f7-459f-f9c0-0b8bd1ddbd31"
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = 50 # Block of data to consider a gesture\n",
    "STEP = 50 # Determines overlapping or not\n",
    "\n",
    "X_train, y_train = create_dataset(\n",
    "      df_train[['x_axis', 'y_axis', 'z_axis']],\n",
    "      df_train.gesture,\n",
    "      TIME_STEPS,\n",
    "      STEP\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1692417573549,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "_g1f1zn3kBqY",
    "outputId": "58e9e478-51cd-4592-ddf4-ee0523d36669"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1643,
     "status": "ok",
     "timestamp": 1692417578451,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "0j9cQj4g4Icj"
   },
   "outputs": [],
   "source": [
    "model = load_model('pre-trained_model.h5')\n",
    "intermediate_model = Model(inputs=model.input, outputs=model.layers[2].output)\n",
    "embeddings_control = intermediate_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1692045785322,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "tf70tZT5qD3P",
    "outputId": "a85ee134-4305-49d1-adb3-1317c64c6a25"
   },
   "outputs": [],
   "source": [
    "embeddings_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1692421476943,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "TvpnmmloaXAI",
    "outputId": "e553dac2-20d2-4d60-ed1b-bf761c7dc640"
   },
   "outputs": [],
   "source": [
    "test_ids = [101] # Impaired subject\n",
    "\n",
    "# order1_label_mapping = {'circle':0, 'double tap':1, 'rotate_f_s':2, 'rotate_s_f':3, 'shake':4, 'tap':5}\n",
    "\n",
    "# order2_label_mapping = {'rotate_s_f':0, 'tap':1, 'rotate_f_s':2, 'shake':3, 'circle':4, 'double tap':5}\n",
    "\n",
    "# order3_label_mapping = {'double tap':0, 'shake':1, 'rotate_f_s':2, 'circle':3, 'tap':4, 'rotate_s_f':5}\n",
    "\n",
    "# order4_label_mapping = {'rotate_f_s':0, 'tap':1, 'circle':2, 'rotate_s_f':3, 'double tap':4, 'shake':5}\n",
    "\n",
    "order5_label_mapping = {'shake':0, 'double tap':1, 'rotate_s_f':2, 'tap':3, 'circle':4, 'rotate_f_s':5}\n",
    "\n",
    "\n",
    "df = read_data('impaired-gesture-data-target.csv', 5, False)\n",
    "df_target = pd.DataFrame(columns=['x_axis', 'y_axis', 'z_axis', 'gesture', 'userId'])\n",
    "df_target = adding_dataframe(df_target, df, test_ids, ['circle', 'double tap', 'rotate_f_s', 'rotate_s_f', 'shake', 'tap'])\n",
    "\n",
    "TIME_STEPS = 50\n",
    "STEP = 50\n",
    "\n",
    "X_target, y_target = create_dataset(\n",
    "      df_target[['x_axis', 'y_axis', 'z_axis']],\n",
    "      df_target.gesture,\n",
    "      TIME_STEPS,\n",
    "      STEP\n",
    "  )\n",
    "print(y_target)\n",
    "\n",
    "y_target = custom_label_encode(y_target, order5_label_mapping)\n",
    "print(y_target)\n",
    "\n",
    "#### Take first 5 samples as train and last 3 samples as test for each gesture ####\n",
    "labels = np.unique(y_target)\n",
    "X_train_target, y_train_target = [], []\n",
    "X_test_target, y_test_target = [], []\n",
    "\n",
    "for label in labels:\n",
    "  c_tr = 0\n",
    "  for ind in range(len(y_target)):\n",
    "    if y_target[ind]==label:\n",
    "      if c_tr<5:\n",
    "        c_tr+=1\n",
    "        X_train_target.append(X_target[ind])\n",
    "        y_train_target.append(y_target[ind])\n",
    "      else:\n",
    "        X_test_target.append(X_target[ind])\n",
    "        y_test_target.append(y_target[ind])\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "X_train_target = np.array(X_train_target)\n",
    "y_train_target = np.array(y_train_target)\n",
    "X_test_target = np.array(X_test_target)\n",
    "y_test_target = np.array(y_test_target)\n",
    "\n",
    "print(X_train_target.shape)\n",
    "print(X_test_target.shape)\n",
    "print(y_train_target)\n",
    "print(y_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1692417598741,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "ee1mLM5BbsUJ"
   },
   "outputs": [],
   "source": [
    "''' Function to add gestures one by one for few shot learning '''\n",
    "\n",
    "def add_gestures(X_local, y_local, number_of_gestures):\n",
    "\n",
    "  X_n, y_n = [], []\n",
    "\n",
    "  for i in range(len(y_local)):\n",
    "    if y_local[i] in np.unique(y_local)[:number_of_gestures]:\n",
    "      X_n.append(X_local[i])\n",
    "      y_n.append(y_local[i])\n",
    "\n",
    "  return X_n, y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1692417602311,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "SXl8mwzHbZ6g"
   },
   "outputs": [],
   "source": [
    "''' Function to plot F1 Score score for each new gesture '''\n",
    "\n",
    "def plot_graph_each_gesture(cls_ges, label, dir_name, image_name):\n",
    "  xaxis = np.array(range(1,6,2))\n",
    "  width = 0.20  # the width of the bars\n",
    "\n",
    "  fig = plt.figure(figsize=(10, 6))\n",
    "  ax = fig.add_subplot(111)\n",
    "  plt.rcParams['font.size'] = 20\n",
    "\n",
    "  gap = 0.00\n",
    "  for item in label:\n",
    "    ax.bar(xaxis + gap, cls_ges[item], width, label=item)\n",
    "    gap+=width\n",
    "\n",
    "  # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "  ax.set_xlabel('Number of samples')\n",
    "  ax.set_ylabel('F1 score')\n",
    "  ax.set_xticks(xaxis+width, xaxis)\n",
    "  ax.set_yticks(np.array(np.arange(0.0, 1.1, 0.1)))\n",
    "  ax.legend()\n",
    "  ax.yaxis.grid(True)\n",
    "\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "  fig.savefig(dir_name + image_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1692417604606,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "TC3ORmAlT1U3"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity_loss(embd_one, embd_two, maximize):\n",
    "    if maximize == True:\n",
    "      cos_sim = cosine_similarity(embd_one, embd_two)\n",
    "      loss = 1.0 - np.mean(cos_sim)\n",
    "    else:\n",
    "      embd_one_flat = np.hstack(embd_one)\n",
    "      embd_two_flat = np.hstack(embd_two)\n",
    "      cos_sim = 1.0 - spatial.distance.cosine(embd_one_flat, embd_two_flat)\n",
    "      loss = - cos_sim\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1692417607125,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "PQorVP7PdNsm"
   },
   "outputs": [],
   "source": [
    "def classification_loss(y_true, y_pred):\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    return loss_object(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1692417608687,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "6uWuXyPBekuu"
   },
   "outputs": [],
   "source": [
    "def overall_loss(model, inputs, targets, embdc, embdif, embdi):\n",
    "  alpha = 0.5 # we choose with 0.5\n",
    "  loss_con_imp = cosine_similarity_loss(embdc, embdi, True)\n",
    "  loss_imp_imp = cosine_similarity_loss(embdif, embdi, False)\n",
    "  loss_cls = classification_loss(targets, model(inputs, training=True))\n",
    "\n",
    "  total_loss = (alpha*loss_con_imp) + ((1-alpha)*loss_imp_imp) + loss_cls\n",
    "\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1692417612567,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "qQ6NgtbXTZPJ"
   },
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets, embdc, embdif, embdi):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = overall_loss(model, inputs, targets, embdc, embdif, embdi)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1692417618439,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "u5ZflQNkTvng"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 590847,
     "status": "ok",
     "timestamp": 1692422084755,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "em_YhgxtI5hF",
    "outputId": "f6908464-453a-4607-eb37-70d5ef318d29"
   },
   "outputs": [],
   "source": [
    "csvfile_prf = open('avg_metric_score_gesture.csv', 'w', encoding='utf-8')\n",
    "csvfile_writer_prf = csv.writer(csvfile_prf)\n",
    "csvfile_writer_prf.writerow([\"number of samples\", \"gesture\", \"avg_precision\", \"avg_recall\", \"avg_f1_score\"])\n",
    "\n",
    "csvfile_acc = open('avg_acc_gesture.csv', 'w', encoding='utf-8')\n",
    "csvfile_writer_acc = csv.writer(csvfile_acc)\n",
    "csvfile_writer_acc.writerow([\"number of samples\", \"number of gestures\", \"avg_accuracy\"])\n",
    "\n",
    "cm = defaultdict(list)\n",
    "\n",
    "number_of_gestures = 6\n",
    "start = 2 # Initilialize with two gestures\n",
    "\n",
    "for cur in range(start, number_of_gestures+1): # Iterate over the gestures. Starts from 0,1.\n",
    "\n",
    "  copy_model = load_model('pre-trained_model.h5')\n",
    "  intermediate_copy_model = Model(inputs=copy_model.input, outputs=copy_model.layers[2].output)\n",
    "\n",
    "  gesture_labels = [i for i in range(cur)] # gesture labels in order\n",
    "\n",
    "  shots = []\n",
    "\n",
    "  cls_ges_pre = defaultdict(list)\n",
    "  cls_ges_rec = defaultdict(list)\n",
    "  cls_ges_f1 = defaultdict(list)\n",
    "\n",
    "  count = 1\n",
    "\n",
    "  X_train_n, y_train_n = add_gestures(X_train_target, y_train_target, cur)\n",
    "  X_test_n, y_test_n = add_gestures(X_test_target, y_test_target, cur)\n",
    "\n",
    "  target_names = list(order5_label_mapping.keys())[:cur]\n",
    "  while (count): # Adding 1 sample, then 3 samples and then 5 samples.\n",
    "    X_train_f = []\n",
    "    y_train_f = []\n",
    "    c={}\n",
    "    for i in gesture_labels:\n",
    "      c[i]=0\n",
    "    for l in range(len(y_train_n)):\n",
    "      if(c[y_train_n[l]]!=count):\n",
    "        X_train_f.append(X_train_n[l])\n",
    "        y_train_f.append(y_train_n[l])\n",
    "        c[y_train_n[l]]+=1\n",
    "\n",
    "    X_train_n_arr = np.array(X_train_f) # Converting list to array (train set)\n",
    "    y_train_n_arr = np.array(y_train_f)\n",
    "\n",
    "    X_test_n_arr = np.array(X_test_n) # Converting list to array (test set)\n",
    "    y_test_n_arr = np.array(y_test_n)\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_train_n_arr = scaler.fit_transform(X_train_n_arr.reshape(-1, X_train_n_arr.shape[-1])).reshape(X_train_n_arr.shape)\n",
    "    X_test_n_arr = scaler.transform(X_test_n_arr.reshape(-1, X_test_n_arr.shape[-1])).reshape(X_test_n_arr.shape)\n",
    "\n",
    "    # Fixed embeddings representation for impaired samples\n",
    "    embeddings_impaired_fixed = intermediate_copy_model(X_train_n_arr)\n",
    "\n",
    "    num_epochs=15\n",
    "\n",
    "  #######################################################\n",
    "    ''' Fine-tuning with LEE '''\n",
    "  #######################################################\n",
    "\n",
    "    cls_ges_sum_pre = defaultdict(list)\n",
    "    cls_ges_sum_rec = defaultdict(list)\n",
    "    cls_ges_sum_f1 = defaultdict(list)\n",
    "    cls_acc = []\n",
    "\n",
    "    for iter in range(10):\n",
    "      train_model = lstm_model(TIME_STEPS, 3, 64, 0.5, 14, 16)\n",
    "      train_model.load_weights('pre-trained_model_weights.h5')\n",
    "      train_model.pop()\n",
    "      train_model.add(Dense(len(gesture_labels), activation='softmax'))\n",
    "      train_model.summary()\n",
    "      for epoch in range(num_epochs):\n",
    "        intermediate_train_model = Model(inputs=train_model.input, outputs=train_model.layers[2].output)\n",
    "        embeddings_impaired = intermediate_train_model(X_train_n_arr)\n",
    "\n",
    "        loss_value, grads = grad(train_model, X_train_n_arr, y_train_n_arr, embeddings_control, embeddings_impaired_fixed, embeddings_impaired)\n",
    "        optimizer.apply_gradients(zip(grads, train_model.trainable_variables))\n",
    "\n",
    "      y_pred = np.argmax(train_model.predict(X_test_n_arr), axis=-1)\n",
    "      cm[cur].append(confusion_matrix(y_test_n_arr, y_pred))\n",
    "\n",
    "      report = classification_report(y_test_n_arr, y_pred, target_names=target_names)\n",
    "\n",
    "      for item in target_names:\n",
    "        precision = float(report.split(item)[1].split()[0])\n",
    "        recall = float(report.split(item)[1].split()[1])\n",
    "        f1_score = float(report.split(item)[1].split()[2])\n",
    "\n",
    "        cls_ges_sum_pre[item].append(precision)\n",
    "        cls_ges_sum_rec[item].append(recall)\n",
    "        cls_ges_sum_f1[item].append(f1_score)\n",
    "\n",
    "      cls_acc.append(float(report.split('accuracy')[1].split()[0]))\n",
    "\n",
    "    for n in target_names:\n",
    "      cls_ges_pre[n].append(np.mean(cls_ges_sum_pre[n]))\n",
    "      cls_ges_rec[n].append(np.mean(cls_ges_sum_rec[n]))\n",
    "      cls_ges_f1[n].append(np.mean(cls_ges_sum_f1[n]))\n",
    "\n",
    "      avg_pre = np.mean(cls_ges_sum_pre[n])\n",
    "      avg_rec = np.mean(cls_ges_sum_rec[n])\n",
    "      avg_f1 = np.mean(cls_ges_sum_f1[n])\n",
    "\n",
    "      csv_line_prf = [count, n, avg_pre, avg_rec, avg_f1]\n",
    "      csvfile_writer_prf.writerow(csv_line_prf)\n",
    "\n",
    "    csv_line_acc = [count, len(gesture_labels), np.mean(cls_acc)]\n",
    "    csvfile_writer_acc.writerow(csv_line_acc)\n",
    "\n",
    "    shots.append(count)\n",
    "    count+=2\n",
    "    if(count>6):\n",
    "      break\n",
    "\n",
    "\n",
    "csvfile_prf.close()\n",
    "csvfile_acc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1692422084756,
     "user": {
      "displayName": "Riyad Bin Rafiq",
      "userId": "11522088134831227343"
     },
     "user_tz": 300
    },
    "id": "15R1mHOMFUVf"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  for key, value in cm.items():\n",
    "    cm[key] = [arr.tolist() for arr in value]\n",
    "\n",
    "  with open('cm_file_order5_lee_101.json', 'w') as f:\n",
    "    json.dump(cm, f)\n",
    "\n",
    "except:\n",
    "  print(\"Not able to save!!!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOS1tDcbd/jLsJm277nO8bc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
